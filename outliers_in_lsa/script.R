##################################################################################
#
# Note: Outliers in Text
#
#		Original text in text_src/real_estate/Set10Tokenized.  That gets parsed
#		with blank lines (no description) removed into text_src/temp/city.txt
#
# 		This file extracted from text.R in C/text.
#
##################################################################################

source("~/C/text/functions.R")

##################################################################################
#
# Response and document lengths
#
##################################################################################

# --- read data generated by C++ (make dolsa)
	city  <- "ChicagoOld3/"

	file    <- paste("~/C/text/text_src/temp/",city,"parsed.txt", sep="")
	Data    <- read.table(file, header=TRUE); dim(Data)

	n         <- nrow(Data)
	logPrice  <- Data[,"Y"]    # file holds log prices
	price     <- exp(Data[,"Y"])
	nTokens   <- Data[,"m"]
	logTokens <- log(nTokens)

# --- lengths (m)
	mean(nTokens); fivenum(nTokens); quantile(nTokens,0.87)
	boxplot(nTokens, horizontal=TRUE, xlab="Lengths of Descriptions")   # boxplot.pdf
	hist(log10(nTokens))

# --- analysis of prices (thousands of $)
	par(mfrow=c(1,2))                                           
		y <- price
		hist(log10(price), breaks=30, main=" ",xlab="log10(Price)")
		qqnorm(log10(price), ylab="log10(Price)"); abline(a=mean(log10(y)),b=sd(log10(y)))
	reset()

# --- simple model for log of prices 
	plot(logPrice ~ logTokens) 
	regr <- lm(logPrice ~ poly(logTokens,5)); summary(regr)
	o <- order(nTokens)
	lines(logTokens[o], fitted.values(regr)[o], col="magenta")


##################################################################################
#  
#   Read word count matrix W
#
##################################################################################
	
	path <- "~/C/text/text_src/temp/ChicagoOld3/"
	
	YM <- as.matrix(read.table(paste(path,"lsa_ym.txt",sep=""),header=T,as.is=T))
	logPrice  <- YM[,1];
	nTokens   <- YM[,2];
	logTokens <- log(YM[,2])
	
	# fix column names when rebuild count matrix to remove embedded quote
	W  <- as.matrix(read.table(paste0(path,"w5704.txt"),header=T,as.is=T))
	# read raw column names to avoid R translation (first line of w5704.txt)
	names <- scan(paste0(path,"types_5704.txt"), what="character")  
	colnames(W) <- names
	type.freq <- colSums(W)


##################################################################################
#
#	Type counts, zipf												zipf.pdf
#
##################################################################################

# --- look at type frequencies, zipf plot

	x<-1:length(type.freq); y<-type.freq
	zipf.data <- data.frame(list(x=x,y=y,lx=log(x),ly=log(y)))

	plot(y~x, xlab="Rank", ylab="Type Frequency", log="xy", data=zipf.data)
	common.words <- c(".", ",", "and", "-", "in")
	text(0.9*x[1:5],0.7*y[1:5],common.words,cex=c(1,1,0.5,1,0.5))

	regr<-lm(ly~lx, data=zipf.data[1:500,]); coefficients(regr)
	lx <- log(x<-c(1,5000)); y <- exp(predict(regr, data.frame(lx=lx)))
	lines(x,y,col="gray")

##################################################################################
#
#     LSA
#
##################################################################################

	nProj   <- 500
	weights <- "cca"
	city    <- "ChicagoOld3/"
	path    <- paste0("~/C/text/text_src/temp/",city)
	file    <- paste0(path,"lsa_",weights,"_", nProj,"_p4_u.txt")
	LSA     <- as.matrix(read.table(file, header=TRUE)); dim(LSA)
	file    <- paste0(path,"lsa_",weights,"_", nProj,"_p4_d.txt")
	D       <- scan(file)
	file    <- paste0(path,"lsa_",weights,"_", nProj,"_p4_v.txt")
	V       <- as.matrix(read.table(file, header=TRUE)); dim(V)

# --- spectrum

	plot(D, xlab="Component", ylab="Log Singular Value", log="xy")	# [ spectrum.pdf ]
	x <- log(2:250);
	y <- log(D[2:250]);
	r <- lm(y~x); coefficients(r)
	pred <- predict(r, newdata=data.frame(x=log(1:400)))
	lines(1:400, exp(pred), col="gray")
	
# --- LSA analysis from matrix W    adj R2=0.7105 with 500 and log tokens^5

	p      <- nProj
	lsa    <- as.matrix(LSA[,2:p])
	sr.lsa <- summary(regr.lsa <- lm(logPrice ~ poly(logTokens,5) + lsa)); sr.lsa
	predictive.r2(regr.lsa)
	
	quartz(width=6.5,height=3); reset()
	coef.summary.plot(sr.lsa, "LSA Component", omit=6)			# [ lsa_tstats.pdf ]  


# --- Which words make up the LSA components?

	plot(V[,1]^2, type.freq)   # nails that one (note that these are CCA scaled)
	
	# plot a component in type freq order 
	x <- 1:nrow(V)
	j <- 17; plot(V[,j],col="gray"); w<-order(abs(V[,j]),decreasing=T)[1:50]; 
	text(x[w],V[w,j],colnames(W)[w],cex=0.75)
	
	# 46 has very clear rays; 8/9 have the auction ray (sale process; also in 12-13)
	# 14-15 is the almost 'ideal' with roughly orthogonal terms; 26-27,50-51 have oblique
	# 18-19 is just interesting; 32-33 has several (weaker) rays
	# Special chars
	# 	20,21,   26 feature asterisk
	#   22,23,25,26 feature tilde ~;
	#   24 is date (2013-06-09) and ---
	#   27 shows the outlier problem
	# Removed: "php?action=listingview&listingid=29" "20-04-416-028-0000" (both in 30)
	# what is "kedvale" and "R3" (in 35,37)  Kedvale is a neighborhood, R3 is a zoning category
	draw.pair <- function(V,j,k=NULL,label="Component") {
		if(is.null(k)) k <- j + 1;
		plot(V[,j],V[,k], col="gray", xlim=1.1*range(V[,j]), ylim=1.1*range(V[,k]),
				xlab=paste(label,j), ylab=paste(label,k)); 
		w<-order(rowSums(V[,c(j,k)]^2),decreasing=T)[1:60]; abline(h=0,v=0,col="gray")
		text(V[w,j],V[w,k],colnames(W)[w],cex=0.7, offset=0.45, pos=c(1,2,3,4,1,2,3,4))
		return(colnames(W)[w[1:20]])
	}
	par(mfrow=c(2,2))								[ lsa_components.pdf ]
		draw.pair(V,5) ; draw.pair(V,8)
		draw.pair(V,23); draw.pair(V,27)
	reset()
	# adding 28 produces the huge jump
	

# --- Rotate the leading k LSA components as in factor analysis
	k <- 250
	vm <- varimax(V[,2:k])				# skip first as its the logToken effect
	v <- vm$loadings
	
	(V[,2:k] %*% vm$rotmat)[1:3,1:6]    # match: V T = new loading matrix
	v[1:3,1:6]
	
	# rotated components are more orthogonal/interpretable in variables
	# factor 1 is pretty cool, kitchen and amenities; #3 is hud, distressed
	# 5-6 is particularly nice; 7-8 gets a clear auction factor; 16 is structure/rooms; 
	#   abbreviated nice things
	# clear structure (though without so much meaning perhaps) even for later terms 100
	# asterisk * is 19; tilde ~ is factor 21 after rotation; --- is 23; 
	#    26 is the outlier variable
	par(mfrow=c(2,2))								# [ rot_components.pdf ]
		draw.pair(v, 7,label="Rotated"); draw.pair(v,16,k=18,label="Rotated")
		draw.pair(v,21,label="Rotated"); draw.pair(v,26,k=31,label="Rotated")
	reset()


# --- LSA analysis from rotated W  
# create new regressors (first is not useful since singular)
	lsa.vm <- LSA[,2:250] %*% vm$rotmat
	colnames(lsa.vm) <- paste0("LVM",1:ncol(lsa.vm))

	sr.rot <- summary(regr.rot <- lm(logPrice ~ poly(logTokens,5) + lsa.vm)); sr.rot
	predictive.r2(regr.rot)    # r2 = 0.6770 with 249
	
	quartz(width=6.5,height=3); reset()
	coef.summary.plot(sr.rot, "Rotated Component", omit=6)			# [ rot_tstats.pdf ]  


	# write these rotated scores out for use in seq_regr for CVSS... manually without " in names
	write.table(lsa, paste0(path,"vmx_2_250.txt"), row.names=F, col.names=T, sep="\t")



##################################################################################
#
#   CV in C++
#
##################################################################################

# --- Write polynomial in tokens for C to use to precondition
#        Note:  Remove quotes from column names *manually* in written file
	poly <- model.matrix(~ poly(logTokens,5) - 1)
	colnames(poly) <- paste("poly_",1:5,sep="")
	write.table(poly, paste(path,"logtoken_poly_5.txt",sep=""), row.names=F)

# --- read C++ CV results; note that these include the collinear term
	cv.results.1.10 <- read.delim(paste(path,"cv_15242/aic_lsa_10f.txt",sep="")) 
	cv.results.2.10 <- read.delim(paste(path,"cv_24387/aic_lsa_10f.txt",sep=""))
	cv.results.3.10 <- read.delim(paste(path,"cv_31427/aic_lsa_10f.txt",sep=""))
	cv.results.4.10 <- read.delim(paste(path,"cv_53853/aic_lsa_10f.txt",sep=""))
	cv.results.5.10 <- read.delim(paste(path,"cv_73241/aic_lsa_10f.txt",sep=""))
		
	cv.results.5.vmx<- read.delim(paste0(path,"cv_73241/aic_vmx_20_2_250.txt")) 


# --- inset plot to show outlier impact					   #  [   cvss.pdf  ]
	x <- 0:(nrow(cv.results.1.10)-1)
	xlim <- NULL;   ylim <- c(3900,9000)	
	par(new = FALSE)
	plot (x,cv.results.1.10[,"AICc"]+2000, log="y", type="l",   xlim=xlim, ylim=ylim, col="red",
			ylab="10-Fold CVSS", xlab="Component Added")   #  [   cvss.pdf  ]
	lines(x,cv.results.1.10 [,"CVSS"], col="black")   # 10 fold
	lines(x,cv.results.2.10 [,"CVSS"], col="black")
	lines(x,cv.results.3.10 [,"CVSS"], col="black")
	lines(x,cv.results.4.10 [,"CVSS"], col="black")
	lines(x,cv.results.5.10 [,"CVSS"], col="black")
	lines(  cv.results.5.vmx[,"CVSS"], col="blue")

	xlim <- c(24,34);   ylim <- c(5000,7500)			# show effect of adding 29 to model
	par(new=TRUE)
	par(fig = c(0.45, 0.90, 0.45, 0.90))
	plot (x,cv.results.1.10[,"AICc"]+2000, log="y", type="l",   xlim=xlim, ylim=ylim, col="red",
			ylab="", xlab="", cex.axis=0.75)  	
	lines(x,cv.results.1.10 [,"CVSS"], col="black")   # 10 fold
	lines(x,cv.results.2.10 [,"CVSS"], col="black")
	lines(x,cv.results.3.10 [,"CVSS"], col="black")
	lines(x,cv.results.4.10 [,"CVSS"], col="black")
	lines(x,cv.results.5.10 [,"CVSS"], col="black")
	par(new=FALSE)
	par(fig = c(0,1,0,1))

# after varimax
	plot(cv.results.5.vmx[,"AICc"], log="y", type="l", xlim=c(1,50),   # varimax
			ylab="Multi-Fold CVSS", xlab="Model Dimension")
	lines(cv.results.5.vmx[,"CVSS"], col="blue")


##################################################################################
#
#   CV in R
#
##################################################################################

	set.seed(23743)
	
	n.folds <- 10	
	n <- length(logPrice)
	folds <- c(rep(1:n.folds,ceiling(n/n.folds)))[1:n]
	folds <- sample(folds,n, replace=F)
	
	# --- whole model, all cases
	#     big outlier/influence point is 3646; most visible in plot of residuals on leverage
	#	  words developmental, training, skills, saint, rose; these are in this and just few
	#     starts to emerge at LSA[,2:26] huge by [,2:28]: (on log scale outlier goes from
	#     -3.8@2:26, -1.4@2:27, -3.8@2:28, -2.0@2:29, -2.6@2:30
	outlier <- 3646
	lsa     <- LSA[,2:30]; 				# avoid L0 which is purely collinear
	# lsa     <- lsa.vm[,1:30]            # already removed L0; larger RSS
	degree  <- 5; 
	r <- lm(logPrice ~ poly(logTokens,degree) + lsa);
	summary(r); c(sum(residuals(r)^2), residuals(r)[outlier])	# 5259.908 for 2:29
	
	# --- via loop, does full sequence of models like seq_regression
	#     use omit to remove special listings
	omit <- NULL # outlier  
	cv.r2 <- cv.sse <- matrix(NA, 1+ncol(lsa), n.folds)
	for(fold in 1:n.folds) {
		cat(fold," ");
		train <- (fold != folds); train[omit] <- F
		data.train <- list(y=logPrice[train], xi=poly(logTokens,degree)[train,], x=lsa[train,])
		test  <- (fold == folds);  test[omit] <- F
		data.test  <- list(y=logPrice[ test], xi=poly(logTokens,degree)[ test,], x=lsa[ test,])
		results <- fit.models(data.train, data.test)
		cv.sse[,fold] <- results$sse
		cv.r2[,fold] <- results$r2
	}

	# --- CVSS jumps up at the addition of var 28
	#     ONE case produces the huge jump in the CVSS in a single fold
	#	  that excludes the outlier
	out.fold <- folds[outlier]   # outlier fold
	cv.sse
	
	# --- show calibration plot with the leverage point			# [   calibrate.pdf  ]
	lsa <- LSA[,2:28]
	i <- (out.fold != folds)
	data <- list(y=logPrice[i], xi=poly(logTokens,degree)[i,], x=lsa[i,])
	r <- lm(y ~ xi + x, data=data );
	i <- (out.fold == folds)
	data <- list(y=logPrice[i], xi=poly(logTokens,degree)[i,], x=lsa[i,])
	pred <- predict(r, newdata=data)
	j <- sum((out.fold==folds)[1:3646]); (logPrice[i]-pred)[j]
	col <- rep("black",sum(i)); col[j]<-"red"
	plot(logPrice[i]-pred, col=col)
	plot(pred, logPrice[i], col=col, xlab="Predicted Log Price", ylab="Log Price") # calibration

# --- find the inversion (CVSS up, AICc down when add row 29 -- which is LSA 28)

	# change is very significant, added variable (L28) highly significant (omit L0 since collinear)
	sr.28 <- lm(logPrice ~ poly(logTokens,5) + LSA[,2:28]); summary(sr.28)$r.squared
	sr.29 <- lm(logPrice ~ poly(logTokens,5) + LSA[,2:29]); summary(sr.29)$r.squared
	anova(sr.28,sr.29)
	
	# partial regr of L28 on L0:L28 is basically nil (R2 < 0.01, but is signficant)
	p.28 <- lm(LSA[,28] ~ poly(logTokens,5) + LSA[,2:27]); summary(p.27)
	p.29 <- lm(LSA[,29] ~ poly(logTokens,5) + LSA[,2:28]); summary(p.28)
	
	plot(sr.28)   # 3646 is highly leveraged (about 0.9)
	plot(sr.29)   # 3646 remains highly leveraged
	
	# partial regression plots
	pr.plot <- function(k) {
		rx <- lm(LSA[,k]  ~ poly(logTokens,5) + LSA[,2:k-1]); 
		ry <- lm(logPrice ~ poly(logTokens,5) + LSA[,2:k-1]); 
		plot(x<-residuals(rx), y<-residuals(ry), 
			xlab=paste("Partial Residuals, k =",k), ylab= "Partial Res log Price")
		abline(r <- lm(y~x));
		ii <- order(hat(x),decreasing=T)[1:5]
		sapply(ii,function(i) text(x[i],y[i],paste(i),pos=3,cex=0.5))
		x <- x[-ii]; y <- y[-ii]
		abline(r <- lm(y~x), col="red");
	}
	# 	observation 3646 is highly leveraged (esp for var 27)
	par(mfrow=c(1,2)	);	mapply(pr.plot,  c(27,28));		reset()		# [ leverage_plots.pdf ]
	
##################################################################################
